# GitHubService.get_user_repositories

**Type:** Today I Learned
**Repository:** kill-pr0cess.inc
**File:** backend/src/services/github_service.rs
**Language:** rust
**Lines:** 125-200
**Complexity:** 10.0

---

## Source Code

```rust
pub async fn get_user_repositories(&self, username: &str) -> Result<Vec<Repository>> {
        let cache_key = format!("github:repos:{}", username);

        // Check cache first - I'm implementing intelligent cache with TTL
        if let Ok(Some(cached_repos)) = self.cache_service.get::<Vec<Repository>>(&cache_key).await {
            debug!("Returning cached repositories for user: {}", username);
            return Ok(cached_repos);
        }

        info!("Fetching fresh repository data for user: {}", username);

        let mut all_repos = Vec::new();
        let mut page = 1;
        let per_page = 100; // Maximum allowed by GitHub API

        loop {
            // I'm checking rate limits before making requests
            self.check_rate_limit().await?;

            let url = format!(
                "{}/users/{}/repos?page={}&per_page={}&sort=updated&direction=desc",
                self.base_url, username, page, per_page
            );

            debug!("Fetching repositories page {} for user: {}", page, username);

            let response = self.client
            .get(&url)
            .send()
            .await
            .map_err(|e| AppError::ExternalApiError(format!("GitHub API request failed: {}", e)))?;

            // Update rate limit information from headers
            self.update_rate_limit_from_headers(&response).await;

            if !response.status().is_success() {
                let status = response.status();
                let error_text = response.text().await.unwrap_or_default();
                return Err(AppError::ExternalApiError(
                    format!("GitHub API error {}: {}", status, error_text)
                ));
            }

            let repos: Vec<GitHubApiRepository> = response
            .json()
            .await
            .map_err(|e| AppError::SerializationError(format!("Failed to parse GitHub response: {}", e)))?;

            if repos.is_empty() {
                break; // No more pages
            }

            // Transform GitHub API response to our internal format
            for api_repo in repos {
                let repo = self.transform_api_repository(api_repo);
                all_repos.push(repo);
            }

            page += 1;

            // Prevent infinite loops and respect API limits
            if page > 50 {
                warn!("Stopping repository fetch at page 50 to prevent excessive API usage");
                break;
            }
        }

        info!("Fetched {} repositories for user: {}", all_repos.len(), username);

        // Cache the results with 1-hour TTL
          if let Err(e) = self.cache_service.set(&cache_key, &all_repos, Some(3600)).await {
            warn!("Failed to cache repository data: {}", e);
        }

        Ok(all_repos)
    }
```

---

## Today I Learned

TIL: This Rust function demonstrates intelligent caching with Time-To-Live (TTL). By checking the cache first and setting it with a 1-hour TTL, it reduces redundant API calls and improves performance efficiently.

```rust
if let Ok(Some(cached_repos)) = self.cache_service.get::<Vec<Repository>>(&cache_key).await {
    debug!("Returning cached repositories for user: {}", username);
    return Ok(cached_repos);
}

// ...

// Cache the results with 1-hour TTL
if let Err(e) = self.cache_service.set(&cache_key, &all_repos, Some(3600)).await {
    warn!("Failed to cache repository data: {}", e);
}
```

This pattern minimizes unnecessary API requests while ensuring fresh data is fetched when needed.

---

*Generated by CodeWorm on 2026-02-21 12:15*
