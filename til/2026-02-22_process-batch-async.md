# _process_batch_async

**Type:** Today I Learned
**Repository:** vuemantics
**File:** backend/workers/batch_processor.py
**Language:** python
**Lines:** 121-212
**Complexity:** 8.0

---

## Source Code

```python
async def _process_batch_async(batch_id: UUID) -> None:
    """
    Async implementation of batch processing

    Args:
        batch_id: UUID of the batch to process
    """
    # Initialize worker thread (idempotent - only runs once per thread)
    await ensure_worker_initialized()

    logger.info(f"Starting batch processing for batch {batch_id}")

    batch = await UploadBatch.find_by_id(batch_id)
    if not batch:
        logger.error(f"Batch {batch_id} not found")
        return

    if batch.status in (BatchStatus.COMPLETED, BatchStatus.CANCELLED):
        logger.info(f"Batch {batch_id} already {batch.status}, skipping")
        return

    await batch.update_status(BatchStatus.PROCESSING)
    logger.info(
        f"Batch {batch_id} marked as processing: "
        f"{batch.total_uploads} uploads to process"
    )

    await publish_batch_progress(batch)

    query = """
        SELECT * FROM uploads
        WHERE batch_id = $1
        ORDER BY created_at ASC
    """
    records = await database.db.fetch(query, batch_id)
    uploads = Upload.from_records(records)

    if len(uploads) != batch.total_uploads:
        logger.warning(
            f"Batch {batch_id} expected {batch.total_uploads} uploads "
            f"but found {len(uploads)}"
        )

    ai_service = LocalAIService()

    for upload in uploads:
        if upload.processing_status == ProcessingStatus.COMPLETED:
            logger.info(
                f"Upload {upload.id} already completed, skipping "
                f"({batch.processed_uploads + 1}/{batch.total_uploads})"
            )
            await batch.increment_progress(successful = True)
            await publish_batch_progress(batch)
            continue

        logger.info(
            f"Processing upload {upload.id} "
            f"({batch.processed_uploads + 1}/{batch.total_uploads})"
        )

        # Publish file progress: starting
        await publish_file_progress(batch, upload, status="processing", progress=0)

        success = await process_upload_with_retry(ai_service, upload, batch)

        # Publish file progress: completed or failed
        final_status = "completed" if success else "failed"
        await publish_file_progress(batch, upload, status=final_status, progress=100)

        await batch.increment_progress(successful = success)
        await publish_batch_progress(batch)

        logger.info(
            f"Upload {upload.id} {'succeeded' if success else 'failed'} "
            f"(batch progress: {batch.processed_uploads}/{batch.total_uploads})"
        )

    if batch.failed_uploads == 0:
        await batch.update_status(BatchStatus.COMPLETED)
        logger.info(
            f"Batch {batch_id} completed successfully: "
            f"{batch.successful_uploads}/{batch.total_uploads} uploads processed"
        )
    else:
        await batch.update_status(BatchStatus.COMPLETED)
        logger.warning(
            f"Batch {batch_id} completed with failures: "
            f"{batch.succes
```

---

## Today I Learned

TIL: In `_process_batch_async`, the function uses asynchronous context management with `await` to handle database queries efficiently, ensuring smooth batch processing without blocking other tasks. This makes the code both readable and performant.

```python
query = """
    SELECT * FROM uploads
    WHERE batch_id = $1
    ORDER BY created_at ASC
"""
records = await database.db.fetch(query, batch_id)
```

This pattern minimizes latency by executing queries asynchronously, crucial for handling large batches efficiently.

---

*Generated by CodeWorm on 2026-02-22 10:20*
