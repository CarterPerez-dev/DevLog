# service

**Type:** File Overview
**Repository:** angelamos-3d
**File:** backend/app/stt/service.py
**Language:** python
**Lines:** 1-85
**Complexity:** 0.0

---

## Source Code

```python
"""
Â©AngelaMos | 2026
service.py
"""

import tempfile
from pathlib import Path

from faster_whisper import WhisperModel

from app.config import settings
from app.core.exceptions import TranscriptionError
from app.stt.schemas import TranscriptionResponse


_model: WhisperModel | None = None


def get_model() -> WhisperModel:
    """
    Lazy-load the Whisper model singleton.
    """
    global _model
    if _model is None:
        device = settings.WHISPER_DEVICE
        compute_type = "int8"

        if device == "auto":
            try:
                import ctranslate2
                if ctranslate2.get_cuda_device_count() > 0:
                    device = "cuda"
                    compute_type = "float16"
                else:
                    device = "cpu"
            except Exception:
                device = "cpu"
        elif device == "cuda":
            compute_type = "float16"

        try:
            _model = WhisperModel(
                settings.WHISPER_MODEL,
                device = device,
                compute_type = compute_type,
            )
        except Exception:
            device = "cpu"
            compute_type = "int8"
            _model = WhisperModel(
                settings.WHISPER_MODEL,
                device = device,
                compute_type = compute_type,
            )
    return _model


async def transcribe(
    audio_data: bytes,
    filename: str
) -> TranscriptionResponse:
    """
    Transcribe audio bytes to text.
    """
    suffix = Path(filename).suffix or ".wav"

    try:
        with tempfile.NamedTemporaryFile(suffix = suffix,
                                         delete = True) as tmp:
            tmp.write(audio_data)
            tmp.flush()

            model = get_model()
            segments, info = model.transcribe(tmp.name, beam_size = 5)
            text_parts = [segment.text for segment in segments]
            full_text = " ".join(text_parts).strip()

        return TranscriptionResponse(
            text = full_text,
            language = info.language,
            duration = info.duration,
        )
    except Exception as e:
        raise TranscriptionError(str(e)) from e

```

---

## File Overview

# service.py Documentation

**Purpose and Responsibility:**
This file provides core functionality for audio transcription using the Whisper model from the `faster-whisper` library. It handles lazy-loading of the model, transcribing audio data to text, and managing temporary files.

**Key Exports or Public Interface:**
- `get_model()`: Lazy-loads a global instance of the Whisper model.
- `transcribe(audio_data: bytes, filename: str) -> TranscriptionResponse`: Asynchronously transcribes provided audio data into text using the loaded model.

**How It Fits in the Project:**
This service is part of the Speech-to-Text (STT) module within the broader backend application. It interacts with the configuration settings and returns structured responses that can be used by other components of the system, such as API endpoints or user interfaces.

**Notable Design Decisions:**
1. **Lazy Loading**: The model is only loaded when needed to optimize memory usage.
2. **Temporary File Handling**: Uses `tempfile` for managing temporary audio files, ensuring they are deleted after use.
3. **Error Handling**: Catches exceptions and raises a custom `TranscriptionError`, providing clear error messages.
4. **Device Selection**: Dynamically selects the appropriate device (CPU or GPU) based on available hardware, optimizing performance.
```

This documentation covers the high-level purpose of the file, its key exports, how it integrates into the project, and highlights some of the design decisions made in the implementation.

---

*Generated by CodeWorm on 2026-02-20 23:59*
