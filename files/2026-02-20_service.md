# service

**Type:** File Overview
**Repository:** fastapi-rc
**File:** fastapi-rc/fastapi_rc/service.py
**Language:** python
**Lines:** 1-243
**Complexity:** 0.0

---

## Source Code

```python
"""
â’¸AngelaMos | 2025
service.py
"""

import json
import logging
from typing import (
    Any,
    TypeVar,
    Generic,
)
from collections.abc import Callable
from collections.abc import Awaitable

from redis.asyncio import Redis
from pydantic import BaseModel

from fastapi_rc.keys import (
    build_cache_key,
    get_ttl_with_jitter,
)


logger = logging.getLogger(__name__)

T = TypeVar("T", bound = BaseModel)


class CacheService(Generic[T]):
    """
    Generic caching service for Pydantic models

    Provides cache-aside pattern with automatic serialization

    Usage:
        user_cache = CacheService(
            redis_client,
            namespace="users",
            model=User,
            default_ttl=600
        )
        user = await user_cache.get("123")
        await user_cache.set("123", user_obj, ttl=600)
    """
    def __init__(
        self,
        redis: Redis,
        namespace: str,
        model: type[T] | None = None,
        default_ttl: int = 300,
        use_jitter: bool = True,
        prefix: str = "cache",
        version: str = "v1",
    ):
        self.redis = redis
        self.namespace = namespace
        self.model = model
        self.default_ttl = default_ttl
        self.use_jitter = use_jitter
        self.prefix = prefix
        self.version = version

    def _build_key(
        self,
        identifier: str,
        params: dict[str, Any] | None = None
    ) -> str:
        """
        Build namespaced cache key
        """
        return build_cache_key(
            self.namespace,
            identifier,
            params,
            prefix = self.prefix,
            version = self.version,
        )

    def _get_ttl(self, ttl: int | None = None) -> int:
        """
        Get TTL with optional jitter
        """
        effective_ttl = ttl or self.default_ttl
        if self.use_jitter:
            return get_ttl_with_jitter(effective_ttl)
        return effective_ttl

    async def get(
        self,
        identifier: str,
        params: dict[str, Any] | None = None,
    ) -> T | None:
        """
        Get cached value, deserialize to Pydantic model if configured
        """
        try:
            key = self._build_key(identifier, params)
            data = await self.redis.get(key)

            if data is None:
                return None

            if self.model:
                return self.model.model_validate_json(data)

            return json.loads(data) if isinstance(data, str) else data

        except Exception as e:
            logger.warning(f"Cache get failed for {identifier}: {e}")
            return None

    async def set(
        self,
        identifier: str,
        value: T | dict[str, Any] | str,
        ttl: int | None = None,
        params: dict[str, Any] | None = None,
    ) -> bool:
        """
        Set cached value with automatic serialization
        """
        try:
            key = self._build_key(identifier, params)
            effective_ttl = self._g
```

---

## File Overview

### service.py

**Purpose:**
This file implements a generic caching service for Pydantic models, providing a cache-aside pattern with automatic serialization/deserialization. It integrates Redis for caching and supports various operations like getting, setting, deleting, and checking the existence of cached values.

**Key Exports:**
- `CacheService[T]`: A generic class for managing cache operations.
  - Methods:
    - `get(identifier, params)`: Retrieves a cached value or `None`.
    - `set(identifier, value, ttl=None, params=None)`: Sets a cached value with an optional TTL.
    - `delete(identifier, params=None)`: Deletes a cached value.
    - `exists(identifier, params=None)`: Checks if a key exists in the cache.
    - `get_or_set(identifier, factory, ttl=None, params=None)`: Retrieves or sets a cached value using a factory function.

**Project Fit:**
This service is part of a larger caching infrastructure for FastAPI applications. It abstracts Redis operations and provides a high-level interface for managing Pydantic model instances in cache, making it easier to integrate caching into various services within the project.

**Design Decisions:**
- **Generics (`T`)**: The `CacheService` class is generic, allowing it to work with any Pydantic model.
- **Automatic Serialization**: Values are automatically serialized/deserialized using Pydantic models or JSON.
- **Jittered TTLs**: TTL values can be jittered for better cache distribution and performance.
- **Error Handling**: Robust error handling ensures that failures in cache operations do not propagate unchecked, logging them instead.
```

This documentation provides a high-level overview of the file's purpose, key exports, integration within the project, and notable design decisions.

---

*Generated by CodeWorm on 2026-02-20 01:34*
