# service

**Type:** File Overview
**Repository:** vuemantics
**File:** backend/services/ai/service.py
**Language:** python
**Lines:** 1-402
**Complexity:** 0.0

---

## Source Code

```python
"""
â’¸AngelaMos | 2026
service.py
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path
from uuid import UUID

import config
from core import VisionError
from core.validators import DescriptionAuditor
from core.websocket import (
    get_publisher,
    ProcessingStage,
    UploadProgressUpdate,
    UploadProgressPayload,
    UploadCompleted,
    UploadFailed,
)
from models.Upload import Upload, ProcessingStatus
from services.storage_service import storage_service
from services.ai.embedding import EmbeddingService
from services.ai.manager import OllamaManager
from services.ai.vision import VisionService


logger = logging.getLogger(__name__)


class LocalAIService:
    """
    Handles AI processing using local Ollama models

    Workflow:
    1. Analyze media with Qwen2.5-VL to get text description
    2. Generate embedding from description using bge-m3
    3. Update upload record with results
    """
    def __init__(self) -> None:
        """
        Initialize local AI service.
        """
        self._ollama = OllamaManager()
        self._vision_semaphore = asyncio.Semaphore(
            config.VISION_SEMAPHORE_LIMIT
        )
        self._embedding_semaphore = asyncio.Semaphore(
            config.EMBEDDING_SEMAPHORE_LIMIT
        )

        self._vision = VisionService(self._ollama, self._vision_semaphore)
        self._embedding = EmbeddingService(
            self._ollama,
            self._embedding_semaphore
        )

        logger.info("Local AI service initialized (Ollama-based)")

    async def _publish_progress(
        self,
        upload_id: UUID,
        status: ProcessingStatus,
        stage: ProcessingStage,
        progress_percent: int,
        message: str,
        error_message: str | None = None,
        audit_score: int | None = None,
    ) -> None:
        """
        Publish upload progress via WebSocket

        Args:
            upload_id: Upload's ID
            status: Current processing status
            stage: Current processing stage
            progress_percent: Progress percentage (0-100)
            message: Human-readable message
            error_message: Error details if failed
            audit_score: Description quality score if available
        """
        try:
            publisher = get_publisher()
            progress_msg = UploadProgressUpdate(
                payload = UploadProgressPayload(
                    upload_id = str(upload_id),
                    status = status,
                    stage = stage,
                    progress_percent = progress_percent,
                    message = message,
                    error_message = error_message,
                    description_audit_score = audit_score,
                ),
                timestamp = datetime.utcnow(),
            )
            await publisher.publish_progress(str(upload_id), progress_msg)
        except Exception as e:
            logger.warning(
                f"Failed to publish 
```

---

## File Overview

### service.py

**Purpose:**
This Python module implements a local AI service for processing media uploads, including analyzing content with Qwen2.5-VL and generating embeddings using bge-m3. It integrates with WebSocket updates to provide real-time progress feedback.

**Key Exports & Public Interface:**
- `LocalAIService`: A class responsible for orchestrating the entire workflow from media analysis to embedding generation.
  - `_publish_progress`: Publishes upload progress via WebSocket.
  - `analyze_media`: Analyzes a media file and generates embeddings, updating the upload record with results.

**Project Integration:**
This service is part of the backend infrastructure handling AI processing tasks. It interacts with other services like storage and WebSocket for real-time updates, ensuring seamless integration into the overall workflow.

**Notable Design Decisions:**
- **Concurrency Control**: Uses `asyncio.Semaphore` to manage concurrency limits for vision and embedding operations.
- **Error Handling & Retries**: Implements retry logic for critical steps with a configurable maximum number of retries.
- **WebSocket Integration**: Utilizes WebSocket updates to provide real-time progress feedback, enhancing user experience.

This module is crucial for ensuring that media uploads are processed efficiently and accurately, leveraging local AI models while maintaining transparency through WebSocket notifications.

---

*Generated by CodeWorm on 2026-02-20 12:22*
