# decorator_pattern

**Type:** Pattern Analysis
**Repository:** CertGames-Core
**File:** backend/api/core/decorators/throttle.py
**Language:** python
**Lines:** 1-127
**Complexity:** 0.0

---

## Source Code

```python
"""
AI Throttle Decorator
Decorator for AI endpoints that applies throttling and guardrails
/api/core/decorators/throttle.py
"""

import logging
from typing import Any
from functools import wraps
from flask import g, jsonify
from collections.abc import Callable

from ..limiters.throttle_helpers import (
    AI_OPERATION_CONFIG,
    DEFAULT_LIMITS,
    extract_input_text,
    limit_input_length,
    check_token_limit,
    log_ai_request,
)


logger = logging.getLogger(__name__)


def ai_throttle(
    operation_type: str,
    *,
    input_field: str | None = None,
    custom_limits: dict[str,
                        int] | None = None,
    model: str | None = None,
    log_usage: bool = True,
    streaming: bool = False,
):
    """
    Decorator for AI endpoints with throttling, token limits and usage tracking
    """
    def decorator(f: Callable) -> Callable:
        @wraps(f)
        def decorated_function(*args: Any, **kwargs: Any) -> Any:
            config: dict[str,
                         Any] = AI_OPERATION_CONFIG.get(
                             operation_type,
                             DEFAULT_LIMITS.copy()
                         )
            if isinstance(config, dict):
                config = config.copy()

            if custom_limits:
                config.update(custom_limits)

            ai_model: str = model or config.get("model", "gpt-4o")

            user_id: str | None = getattr(g, "user_id", None)

            input_text: str | None = extract_input_text(input_field)
            if not input_text:
                return jsonify({"error": "No input text provided"}), 400

            limited_text: str | None = limit_input_length(
                input_text,
                operation_type = operation_type,
                custom_max = config.get("max_chars")
            )

            is_within_limit: bool
            estimated_tokens: int
            is_within_limit, estimated_tokens = check_token_limit(
                limited_text,
                operation_type=operation_type,
                custom_max=config.get("max_tokens"),
            )

            if not is_within_limit:
                max_tokens: int = config.get(
                    "max_tokens",
                    DEFAULT_LIMITS["max_tokens"]
                )
                error_msg: str = (
                    f"Input exceeds maximum token limit. "
                    f"Estimated: {estimated_tokens} tokens, Maximum: {max_tokens} tokens. "
                    f"Please use shorter input."
                )

                if streaming:

                    def error_generator():
                        yield error_msg

                    return error_generator()

                return jsonify({"error": error_msg, "type": "token_limit_exceeded"}), 400

            log_id: str | None = None
            if log_usage:
                try:
                    log_id = log_ai_request(
                        user_id = user_id,
                        op
```

---

## Pattern Analysis

### Pattern Analysis

**Pattern Used:** Decorator Pattern

The `ai_throttle` decorator in this code implements the **Decorator Pattern**, which allows behavior to be added to an individual object, either statically or dynamically, without affecting the structure of other objects.

- **Implementation**: The `ai_throttle` function returns a decorator that wraps another function (`f`). This inner decorator (`decorator`) then adds functionality (throttling and logging) before calling the original function.
  
- **Benefits**:
  - **Modularity**: The decorator can be reused across different AI endpoints without modifying their core logic.
  - **Flexibility**: Custom limits and models can be specified dynamically, enhancing adaptability.
  - **Maintainability**: Centralized throttling and logging logic simplifies maintenance.

- **Deviations**:
  - The decorator sets attributes on the decorated function (`g.ai_input`, `g.ai_model`, etc.), which is not typical of standard decorators but helps with state management within the application context.
  - It uses a custom error generator for streaming responses, diverging from traditional return values.

- **Appropriateness**:
  - This pattern is suitable when you need to add cross-cutting concerns like logging and throttling across multiple functions without modifying their core logic. It's particularly useful in web frameworks where such behaviors are common.

This implementation effectively encapsulates the functionality of AI endpoint management, making it a good fit for this context.

---

*Generated by CodeWorm on 2026-02-22 17:22*
