# factory

**Type:** Pattern Analysis
**Repository:** CertGames-Core
**File:** backend/api/domains/tools/qa/conftest.py
**Language:** python
**Lines:** 1-408
**Complexity:** 0.0

---

## Source Code

```python
"""
Tools Domain Test Configuration
/api/domains/tools/qa/conftest.py
"""

import pytest
from typing import Any
from collections.abc import Generator
from unittest.mock import MagicMock, Mock

from qa.conftest import (
    app,
    client,
    db,
    redis_client,
    audit_capture,
    api_client,
    valid_object_id,
    flask_g,
)
from qa.account_qa.fixtures.factories import (
    comprehensive_user_factory,
)
from qa.account_qa.fixtures.auth import (
    enhanced_auth_headers,
)
from qa.super_global.fixtures.database import (
    db_state_manager,
    isolated_db_test,
    seeded_db_test,
)


@pytest.fixture
def mock_openai_streaming():
    """
    Mock OpenAI client with streaming support for tools domain
    """
    class MockStreamChunk:
        """
        Mock a streaming chunk from OpenAI
        """
        def __init__(
            self,
            content: str | None = None,
            usage_data: dict | None = None
        ):
            self.choices = [
                MagicMock(delta = MagicMock(content = content))
            ]
            if usage_data:
                self.usage = MagicMock(
                    prompt_tokens = usage_data.get('prompt_tokens',
                                                   100),
                    completion_tokens = usage_data.get(
                        'completion_tokens',
                        50
                    )
                )
            else:
                self.usage = None

    class MockOpenAIClient:
        """
        Mock OpenAI client with streaming capabilities
        """
        def __init__(self):
            self.chat = MagicMock()
            self.chat.completions = MagicMock()

        def create_streaming_response(
            self,
            content:
            str = "This is a mocked AI response for testing purposes.",
            chunks: list[str] | None = None
        ):
            """
            Create a mock streaming response
            """
            if chunks is None:
                words = content.split()
                chunks = [word + " " for word in words]

            def stream_generator():
                for chunk_content in chunks:
                    yield MockStreamChunk(content = chunk_content)

                yield MockStreamChunk(
                    content = None,
                    usage_data = {
                        'prompt_tokens': 100,
                        'completion_tokens': len(chunks) * 5
                    }
                )

            return stream_generator()

        def create_error_response(self, error_msg: str = "API Error"):
            """
            Create a mock error response
            """
            def error_generator():
                raise Exception(error_msg)
                yield

            return error_generator()

    return MockOpenAIClient()


@pytest.fixture
def mock_openai_client(app, mock_openai_streaming):
    """
    Mock OpenAI client in Flask app extensions
    """
 
```

---

## Pattern Analysis

### Pattern Analysis

**Pattern Used:** Factory Method

The `mock_openai_streaming` and `mock_ai_throttle` fixtures in the provided code implement a **Factory Method** design pattern. Specifically, these fixtures create mock objects that simulate the behavior of real OpenAI client and AI throttling functionalities.

#### Implementation
- The `mock_openai_streaming` fixture defines a class `MockOpenAIClient` with methods to generate mock streaming responses and error responses.
- Similarly, `mock_ai_throttle` uses monkeypatching to replace functions in the `throttle_helpers` module with mocks that return predefined behaviors.

#### Benefits
1. **Isolation:** These fixtures isolate the test from external dependencies like OpenAI API, ensuring tests are independent of network or service availability.
2. **Controlled Testing:** They provide precise control over the behavior of the mock objects, allowing for detailed testing scenarios (e.g., streaming responses, error handling).
3. **Reusability:** The factory methods can be reused across multiple test cases, reducing code duplication.

#### Deviations
- The `mock_openai_streaming` fixture uses a generator to yield mock stream chunks, which is an advanced implementation of the Factory Method.
- `mock_ai_throttle` leverages monkeypatching, which is not part of the standard Factory Method but enhances flexibility in modifying behavior dynamically during tests.

#### Appropriate Use
This pattern is highly appropriate for unit testing scenarios where you need to simulate complex interactions or external services. It ensures that your tests are robust and reliable by providing controlled and predictable mock objects. However, it might be overkill for simpler test cases where direct mocking would suffice.

---

*Generated by CodeWorm on 2026-02-23 17:19*
