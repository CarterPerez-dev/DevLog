# GetGPUProcesses

**Type:** Documentation
**Repository:** Yoshi-Audit
**File:** internal/system/gpu.go
**Language:** go
**Lines:** 69-109
**Complexity:** 8.0

---

## Source Code

```go
func GetGPUProcesses() ([]GPUProcess, error) {
	out, err := exec.Command(
		"nvidia-smi",
		"--query-compute-apps=pid,used_memory",
		"--format=csv,noheader,nounits",
	).Output()
	if err != nil {
		return nil, fmt.Errorf("nvidia-smi failed: %w", err)
	}

	var procs []GPUProcess
	lines := strings.Split(strings.TrimSpace(string(out)), "\n")
	for _, line := range lines {
		line = strings.TrimSpace(line)
		if line == "" || strings.HasPrefix(line, "[") {
			continue
		}

		parts := strings.Split(line, ",")
		if len(parts) < 2 {
			continue
		}

		pid, err := strconv.Atoi(strings.TrimSpace(parts[0]))
		if err != nil {
			continue
		}

		memMiB, err := strconv.ParseUint(strings.TrimSpace(parts[1]), 10, 64)
		if err != nil {
			continue
		}

		procs = append(procs, GPUProcess{
			PID:      pid,
			UsedVRAM: memMiB * 1024 * 1024,
		})
	}

	return procs, nil
}
```

---

## Documentation

### Documentation for `GetGPUProcesses`

**Purpose and Behavior:**
`GetGPUProcesses` retrieves a list of processes using the GPU by executing the `nvidia-smi` command with specific query parameters. It parses the output to extract process IDs (PIDs) and used VRAM in MiB, converting them into a structured slice of `GPUProcess`.

**Key Implementation Details:**
- The function uses `exec.Command` to run `nvidia-smi`, querying for PIDs and VRAM usage.
- Output is parsed line by line, filtering out empty or invalid lines.
- Each valid line is split into PID and used memory, converting these values appropriately before adding them to the `GPUProcess` slice.

**When/Why to Use This Code:**
Use this function when you need real-time monitoring of GPU usage across processes. It's particularly useful in performance analysis tools or during debugging sessions where understanding which applications are consuming significant VRAM is crucial.

**Patterns and Gotchas:**
- **Error Handling:** The function uses `fmt.Errorf` for error formatting, ensuring that any failure to execute `nvidia-smi` is properly reported.
- **Resource Management:** Ensure the `nvidia-smi` command is available on the system before calling this function. Missing or misconfigured `nvidia-smi` can lead to unexpected behavior.
- **Performance Considerations:** Parsing large outputs from `nvidia-smi` could be resource-intensive; consider optimizing if used in high-frequency monitoring scenarios.

---

*Generated by CodeWorm on 2026-03-01 00:22*
