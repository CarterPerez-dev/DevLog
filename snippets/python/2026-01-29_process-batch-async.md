# _process_batch_async

**Repository:** vuemantics
**File:** backend/workers/batch_processor.py
**Language:** python
**Lines:** 121-212
**Complexity:** 8.0

---

## Source Code

```python
async def _process_batch_async(batch_id: UUID) -> None:
    """
    Async implementation of batch processing

    Args:
        batch_id: UUID of the batch to process
    """
    # Initialize worker thread (idempotent - only runs once per thread)
    await ensure_worker_initialized()

    logger.info(f"Starting batch processing for batch {batch_id}")

    batch = await UploadBatch.find_by_id(batch_id)
    if not batch:
        logger.error(f"Batch {batch_id} not found")
        return

    if batch.status in (BatchStatus.COMPLETED, BatchStatus.CANCELLED):
        logger.info(f"Batch {batch_id} already {batch.status}, skipping")
        return

    await batch.update_status(BatchStatus.PROCESSING)
    logger.info(
        f"Batch {batch_id} marked as processing: "
        f"{batch.total_uploads} uploads to process"
    )

    await publish_batch_progress(batch)

    query = """
        SELECT * FROM uploads
        WHERE batch_id = $1
        ORDER BY created_at ASC
    """
    records = await database.db.fetch(query, batch_id)
    uploads = Upload.from_records(records)

    if len(uploads) != batch.total_uploads:
        logger.warning(
            f"Batch {batch_id} expected {batch.total_uploads} uploads "
            f"but found {len(uploads)}"
        )

    ai_service = LocalAIService()

    for upload in uploads:
        if upload.processing_status == ProcessingStatus.COMPLETED:
            logger.info(
                f"Upload {upload.id} already completed, skipping "
                f"({batch.processed_uploads + 1}/{batch.total_uploads})"
            )
            await batch.increment_progress(successful = True)
            await publish_batch_progress(batch)
            continue

        logger.info(
            f"Processing upload {upload.id} "
            f"({batch.processed_uploads + 1}/{batch.total_uploads})"
        )

        # Publish file progress: starting
        await publish_file_progress(batch, upload, status="processing", progress=0)

        success = await process_upload_with_retry(ai_service, upload, batch)

        # Publish file progress: completed or failed
        final_status = "completed" if success else "failed"
        await publish_file_progress(batch, upload, status=final_status, progress=100)

        await batch.increment_progress(successful = success)
        await publish_batch_progress(batch)

        logger.info(
            f"Upload {upload.id} {'succeeded' if success else 'failed'} "
            f"(batch progress: {batch.processed_uploads}/{batch.total_uploads})"
        )

    if batch.failed_uploads == 0:
        await batch.update_status(BatchStatus.COMPLETED)
        logger.info(
            f"Batch {batch_id} completed successfully: "
            f"{batch.successful_uploads}/{batch.total_uploads} uploads processed"
        )
    else:
        await batch.update_status(BatchStatus.COMPLETED)
        logger.warning(
            f"Batch {batch_id} completed with failures: "
            f"{batch.successful_uploads} succeeded, "
            f"{batch.failed_uploads} failed out of {batch.total_uploads}"
        )

    await publish_batch_progress(batch)
```

---

## Documentation

### Documentation for `_process_batch_async` Function

**Purpose and Behavior:**
The function `async def _process_batch_async(batch_id: UUID) -> None` is an asynchronous batch processing handler in a worker thread. It processes a batch of uploads, updating the batch status and individual upload statuses as it goes.

**Key Implementation Details:**
1. **Initialization:** Ensures the worker thread is initialized.
2. **Batch Fetching & Validation:** Retrieves and validates the batch by its ID; skips if already completed or cancelled.
3. **Upload Processing Loop:** Iterates over each upload, processes them with retries, and updates progress and statuses accordingly.
4. **Status Updates:** Regularly publishes batch and file progress to a message broker.

**When/Why to Use:**
Use this function in scenarios where you need to process large batches of uploads asynchronously, ensuring efficient handling and tracking of individual uploads within the batch. It's ideal for background tasks that require monitoring and error recovery.

**Patterns & Gotchas:**
- **Idempotency:** The worker initialization is idempotent, meaning it only runs once per thread.
- **Error Handling:** Skips completed or cancelled batches early to avoid unnecessary processing.
- **Concurrency:** Asynchronous nature allows for efficient handling of multiple uploads in parallel.
- **Retry Mechanism:** `process_upload_with_retry` ensures robust upload processing with retries.

---

*Generated by CodeWorm on 2026-01-29 13:09*
