# PerformanceMetric.create_sample

**Repository:** CertGames-Core
**File:** backend/api/admin/models/analytics/PerformanceMetric.py
**Language:** python
**Lines:** 71-115
**Complexity:** 7.0

---

## Source Code

```python
def create_sample(
        cls,
        endpoint: str,
        response_times: list[float],
        *,
        error_count: int = 0,
        db_times: list[float] | None = None,
        user_ids: list[str] | None = None,
        **kwargs
    ) -> PerformanceMetric:
        """
        Create a performance metric sample from raw data.
        """
        if not response_times:
            raise ValidationError("response_times cannot be empty")

        sorted_times = sorted(response_times)
        count = len(sorted_times)

        metric = cls(
            endpoint = endpoint,
            request_count = count,
            error_count = error_count,
            avg_response_time = sum(sorted_times) / count,
            min_response_time = sorted_times[0],
            max_response_time = sorted_times[-1],
            p50_response_time = sorted_times[int(count * 0.5)],
            p95_response_time = sorted_times[int(count * 0.95)],
            p99_response_time = sorted_times[int(count * 0.99)]
            if count > 100 else sorted_times[-1],
        )

        if db_times:
            metric.avg_db_queries = len(db_times) / count
            metric.avg_db_time = sum(db_times) / len(db_times)

        if user_ids:
            metric.unique_users = len(set(user_ids))

        for key, value in kwargs.items():
            if hasattr(metric, key):
                setattr(metric, key, value)

        metric.save()
        return metric
```

---

## Documentation

### Documentation for `PerformanceMetric.create_sample`

**Purpose and Behavior**
The `create_sample` method generates a `PerformanceMetric` instance from raw performance data, including response times, error counts, database query times, user IDs, and additional custom attributes. It calculates various metrics like average, minimum, maximum, and percentile response times.

**Key Implementation Details**
- **Class Method**: Uses the `@classmethod` decorator to operate on class objects.
- **Type Hints**: Clearly defines input types for parameters such as `response_times`, `error_count`, `db_times`, and `user_ids`.
- **Validation**: Ensures `response_times` are not empty, raising a `ValidationError` if they are.
- **Metrics Calculation**: Computes average response times, percentiles, and unique user counts based on provided data.

**When/Why to Use This Code**
Use this method when you need to create performance metrics from raw data collected during API requests. It is particularly useful for generating analytics reports or monitoring system performance over time.

**Patterns and Gotchas**
- **Default Parameters**: `error_count` and `db_times/user_ids` are optional, allowing flexibility in the input.
- **Dynamic Attributes**: The method dynamically sets attributes based on `kwargs`, making it adaptable to varying data structures.
- **Potential Errors**: Ensure that `response_times` are provided; otherwise, a `ValidationError` will be raised.

---

*Generated by CodeWorm on 2026-01-21 19:01*
