# stream_chat

**Type:** Documentation
**Repository:** angelamos-3d
**File:** backend/app/chat/service.py
**Language:** python
**Lines:** 35-53
**Complexity:** 4.0

---

## Source Code

```python
async def stream_chat(messages: list[Message]) -> AsyncGenerator[bytes, None]:
    """
    Stream chat responses from Ollama.
    """
    payload = build_payload(messages, stream = True)

    try:
        async with httpx.AsyncClient() as client:  # noqa: SIM117
            async with client.stream(
                    "POST",
                    f"{settings.OLLAMA_HOST}/api/chat",
                    json = payload,
                    timeout = settings.OLLAMA_TIMEOUT,
            ) as response:
                async for line in response.aiter_lines():
                    if line:
                        yield line.encode() + b"\n"
    except httpx.ConnectError as e:
        raise OllamaConnectionError() from e
```

---

## Documentation

### Documentation for `stream_chat` Function

**Purpose and Behavior:**
The `stream_chat` function streams chat responses from the Ollama API by sending a POST request with a payload containing multiple messages. It processes the response line-by-line, encoding each non-empty line as bytes prefixed with a newline character.

**Key Implementation Details:**
- **Asynchronous Context Managers:** Utilizes `httpx.AsyncClient()` for asynchronous HTTP requests and handles streaming responses.
- **Payload Construction:** The `payload` is built using the `build_payload` function with the `stream=True` parameter to enable streaming.
- **Error Handling:** Catches `httpx.ConnectError`, raising a custom `OllamaConnectionError` if a connection issue occurs.

**When/Why to Use:**
Use this code when you need to efficiently stream chat responses from Ollama in real-time, especially for applications requiring low-latency communication. It is particularly useful for handling large payloads or long-running chat sessions without blocking the event loop.

**Patterns and Gotchas:**
- **Resource Management:** Properly uses `async with` statements to ensure resources are managed correctly.
- **Line-by-Line Processing:** Efficiently processes streaming responses, ensuring minimal memory usage by encoding lines on-the-fly.

---

*Generated by CodeWorm on 2026-02-27 21:23*
