# DocumentationGenerator

**Type:** Class Documentation
**Repository:** CodeWorm
**File:** codeworm/llm/generator.py
**Language:** python
**Lines:** 143-332
**Complexity:** 0.0

---

## Source Code

```python
class DocumentationGenerator:
    """
    Generates documentation for code snippets using LLM
    """
    def __init__(
        self,
        client: OllamaClient,
        prompt_settings: PromptSettings | None = None,
    ) -> None:
        """
        Initialize generator with Ollama client and optional prompt settings
        """
        self.client = client
        self.prompt_settings = prompt_settings
        self.prompt_builder = PromptBuilder(settings = prompt_settings)

    async def generate(
        self,
        candidate: AnalysisCandidate
    ) -> GeneratedDocumentation:
        """
        Generate documentation for a candidate
        """
        start_time = datetime.now()

        system, user = build_documentation_prompt(candidate, self.prompt_settings)
        doc_result = await self.client.generate_with_retry(user, system)
        documentation = self._clean_documentation(doc_result.text)

        system, user = build_commit_prompt(documentation, candidate, self.prompt_settings)
        commit_result = await self.client.generate(
            user,
            system,
            temperature = 0.4
        )
        commit_message = self._clean_commit_message(commit_result.text)

        generation_time = int(
            (datetime.now() - start_time).total_seconds() * 1000
        )
        total_tokens = doc_result.total_tokens + commit_result.total_tokens

        filename = self._generate_filename(candidate)

        logger.info(
            "documentation_generated",
            function = candidate.snippet.display_name,
            repo = candidate.snippet.repo,
            tokens = total_tokens,
            time_ms = generation_time,
        )

        return GeneratedDocumentation(
            content = documentation,
            commit_message = commit_message,
            snippet_filename = filename,
            generated_at = datetime.now(),
            tokens_used = total_tokens,
            generation_time_ms = generation_time,
        )

    async def generate_from_target(
        self,
        target: DocumentationTarget,
    ) -> GeneratedDocumentation:
        """
        Generate documentation for a DocumentationTarget with any doc_type
        """
        start_time = datetime.now()

        system, user = self.prompt_builder.build_target_prompt(target)
        doc_result = await self.client.generate_with_retry(user, system)
        documentation = self._clean_documentation(doc_result.text)

        commit_context_name = target.display_name
        doc_type_label = DOC_TYPE_LABELS.get(target.doc_type, "docs")
        commit_system = (
            "You generate natural, human sounding git commit messages. "
            "Be concise and specific."
        )
        commit_user = (
            f"Generate a commit message for this {doc_type_label.lower()}:\n\n"
            f"{documentation[:500]}\n\n"
            f"Code context: {commit_context_name} in {target.snippet.language.value} "
            f"from {target.
```

---

## Class Documentation

### DocumentationGenerator Class

**Responsibility and Purpose**: 
The `DocumentationGenerator` class is responsible for generating documentation and commit messages using an LLM (Large Language Model) client. It leverages a prompt builder to construct appropriate prompts based on input candidates or targets, ensuring that generated content adheres to specific guidelines.

**Public Interface**:
- **__init__**: Initializes the generator with an `OllamaClient` and optional `PromptSettings`.
- **generate**: Generates documentation for a given `AnalysisCandidate`.
- **generate_from_target**: Generates documentation for a `DocumentationTarget`, including commit messages.

**Design Patterns Used**:
The class employs the **Strategy Pattern** through the use of `PromptBuilder` to dynamically construct prompts based on different input types. This allows for flexible and adaptable prompt generation without modifying existing code.

**Relationship to Other Classes**:
- **OllamaClient**: Communicates with the LLM to generate text.
- **PromptSettings**: Configures the behavior of the prompt builder.
- **AnalysisCandidate**, **DocumentationTarget**: Provide context for generating documentation and commit messages.
- **GeneratedDocumentation**: Represents the output of the generation process.

**State Management Approach**:
The class maintains state through instance variables like `client`, `prompt_settings`, and `prompt_builder`. The `_generate_target_filename` method manages file naming conventions, ensuring consistent and meaningful filenames.

---

*Generated by CodeWorm on 2026-02-19 13:14*
