# description

**Type:** Code Evolution
**Repository:** vuemantics
**File:** backend/core/validators/description.py
**Language:** python
**Lines:** 1-1
**Complexity:** 0.0

---

## Source Code

```python
Commit: 4d33b24a
Message: feat: dramatiq - bulkupload
Author: CarterPerez-dev
File: backend/core/validators/description.py
Change type: modified

Diff:
@@ -4,6 +4,7 @@ Description validation and audit logic.
 Sanity checks AI-generated descriptions for hallucinations and gibberish.
 """
 
+import re
 from dataclasses import dataclass
 from typing import ClassVar
 
@@ -49,11 +50,14 @@ class DescriptionAuditor:
 
         text = description.strip()
 
+        score, issues = cls._check_complete_garbage(text, score, issues)
         score, issues = cls._check_bad_tokens(text, score, issues)
         score, issues = cls._check_length(text, score, issues)
         score, issues = cls._check_word_diversity(text, score, issues)
         score, issues = cls._check_consecutive_repeats(text, score, issues)
         score, issues = cls._check_gibberish_ratio(text, score, issues)
+        score, issues = cls._check_sentence_structure(text, score, issues)
+        score, issues = cls._check_common_words(text, score, issues)
 
         final_score = max(0, score)
         passed = final_score >= config.DESCRIPTION_AUDIT_PASS_THRESHOLD
@@ -64,6 +68,146 @@ class DescriptionAuditor:
             passed = passed
         )
 
+    @classmethod
+    def _check_complete_garbage(cls,
+                                text: str,
+                                score: int,
+                                issues: list[str]) -> tuple[int,
+                                                            list[str]]:
+        """
+        Check if description is complete garbage (mostly random special chars).
+        This catches catastrophic AI failures that produce gibberish.
+        """
+        if len(text) == 0:
+            return score, issues
+
+        # Check alpha ratio
+        alphabetic = sum(1 for c in text if c.isalpha())
+        alpha_ratio = alphabetic / len(text)
+
+        if alpha_ratio < 0.3:
+            score -= 70
+            issues.append(
+                f"Complete garbage: only {alpha_ratio:.1%} alphabetic characters"
+            )
+            return score, issues
+
+        # Check for random character sequences (e.g., "4#2>*)=-C4>8B")
+        # Real text doesn't mix letters, numbers, and special chars randomly
+        tokens = re.findall(r'[^\s]+', text)
+        garbage_tokens = 0
+
+        for token in tokens[:100]:  # Check first 100 tokens
+            # Count different character types
+            letters = sum(1 for c in token if c.isalpha())
+            digits = sum(1 for c in token if c.isdigit())
+            special = sum(1 for c in token if not c.isalnum())
+
+            # If token has all three types and is short, it's likely garbage
+            if len(token) <= 15 and letters > 0 and digits > 0 and special > 2:
+                garbage_tokens += 1
+
+        garbage_ratio = garbage_tokens / len(tokens) if tokens else 0
+
+        if garbage_ratio > 0.3:
+            score -= 80
+            issues.append(
+                
```

---

## Code Evolution

### Change Analysis

**What was Changed:**
The commit introduces three new methods in the `DescriptionAuditor` class: `_check_complete_garbage`, `_check_sentence_structure`, and `_check_common_words`. These methods enhance the validation logic to better identify AI-generated gibberish, ensure proper sentence structure, and detect common words. The changes are spread across lines 49-68 and include new import statements and method definitions.

**Why it was Likely Changed:**
The additions aim to improve the robustness of description validation by addressing specific issues that might arise from AI-generated text. `_check_complete_garbage` helps identify descriptions with minimal alphabetic content, `_check_sentence_structure` ensures proper sentence formation, and `_check_common_words` detects common English words often missing in gibberish.

**Impact on Behavior:**
These new checks will likely reduce false positives by catching more cases of AI-generated gibberish. The validation process now includes a broader set of criteria, potentially leading to more accurate audits.

**Risks or Concerns:**
While these changes improve validation, they might introduce complexity and potential performance overhead due to additional regex operations. Ensuring that the new checks do not inadvertently penalize valid but unconventional descriptions is crucial. Additionally, the threshold for passing the audit should be carefully tuned to balance between false positives and negatives.

---

*Generated by CodeWorm on 2026-02-23 10:18*
