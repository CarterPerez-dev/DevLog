# scrub

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/beginner/metadata-scrubber-tool/src/commands/scrub.py
**Language:** python
**Lines:** 36-150
**Complexity:** 10.0

---

## Source Code

```python
def scrub(
    file_path: Path = typer.Argument(
        exists=True,
        file_okay=True,
        dir_okay=True,
        readable=True,
        writable=True,
        resolve_path=True,
        help="The file or directory to process.",
    ),
    recursive: bool = typer.Option(
        False, "--recursive", "-r",
        help="Recursively process files in the specified directory."
    ),
    ext: str = typer.Option(
        None, "--extension", "-ext",
        help="File extension to filter by (e.g., jpg, png)."
    ),
    output_dir: str = typer.Option(
        "./scrubbed", "--output", "-o",
        help="Directory to save processed files."
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", "-d",
        help="Preview what would be processed without making changes."
    ),
    workers: int = typer.Option(
        min(4, (os.cpu_count() or 1)),
        "--workers", "-w",
        help="Number of concurrent worker threads (default: 4 or CPU count)."
    ),
):
    # fmt: on
    """
    Remove metadata from files.

    Scrubs privacy-sensitive metadata (EXIF, GPS, author info) from images.
    Works with JPEG, PNG, and will support PDF/Office docs in future.

    Examples:

        scrub photo.jpg

        scrub ./photos/ -r -ext jpg --output ./cleaned

        scrub ./folder/ -r -ext png --dry-run

        scrub ./large_batch/ -r -ext jpg --workers 8
    """
    # Validate recursive/extension combo
    if recursive and not ext:
        raise typer.BadParameter(
            "If you provide --recursive or -r, you must also provide --extension or -ext."
        )
    if ext and not recursive:
        raise typer.BadParameter(
            "If you provide --extension or -ext, you must also provide --recursive or -r."
        )

    # Show dry-run banner
    if dry_run:
        console.print(
            "\n[bold yellow]ðŸ” DRY-RUN MODE[/bold yellow] - No files will be modified.\n"
        )

    # Collect files to process
    files = list(get_target_files(file_path, ext)) if recursive else [file_path]

    if not files:
        console.print("[yellow]No files found to process.[/yellow]")
        raise typer.Exit(0)

    # Show worker count for batch operations
    if len(files) > 1:
        console.print(
            f"[dim]Processing {len(files)} files with {workers} workers...[/dim]\n"
        )

    # Initialize processor with worker count
    processor = BatchProcessor(
        output_dir = output_dir,
        dry_run = dry_run,
        max_workers = workers
    )

    # Process with thread-safe progress bar
    with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            MofNCompleteColumn(),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console = console,
            refresh_per_second = 10,  # Smooth updates for concurrent processing
    ) as progress:
        task_id = progress.add_task(
            "[cyan]
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The time complexity is primarily driven by the `processor.process_batch(files, progress_callback = on_file_complete)` call, which processes each file concurrently using a thread pool. Assuming `N` files and `W` workers, the effective time complexity can be approximated as \( O(N) \), but with potential overhead from context switching and thread management.

**Space Complexity:** The space complexity is \( O(W + N) \), where \( W \) is the number of worker threads and \( N \) is the number of files. This includes memory for file paths, progress tracking, and any intermediate data structures used by `BatchProcessor`.

**Bottlenecks or Inefficiencies:**
- **Redundant File Checks:** The recursive check can be optimized to avoid redundant calls.
- **Progress Callback Overhead:** Frequent updates to the progress bar might introduce overhead. Consider batching these updates.

**Optimization Opportunities:**
- **Lazy Initialization:** Initialize `processor` and `progress` only when necessary, reducing unnecessary object creation.
- **Batch Processing Optimization:** Ensure that `BatchProcessor.process_batch()` is optimized for concurrent processing without redundant operations.

**Resource Usage Concerns:**
- **File Path Validation:** Ensure that file paths are validated efficiently to avoid potential errors.
- **Progress Bar Updates:** Optimize the frequency of progress bar updates to balance between performance and user feedback.

By addressing these areas, you can enhance both the efficiency and responsiveness of your metadata scrubbing tool.

---

*Generated by CodeWorm on 2026-02-18 16:27*
