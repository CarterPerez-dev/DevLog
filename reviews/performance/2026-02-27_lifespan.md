# lifespan

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/advanced/ai-threat-detection/backend/app/factory.py
**Language:** python
**Lines:** 31-117
**Complexity:** 5.0

---

## Source Code

```python
async def lifespan(app: FastAPI) -> AsyncIterator[None]:
    """
    Manage application startup and shutdown lifecycle.
    """
    app.state.startup_time = time.monotonic()
    app.state.pipeline_running = False

    engine = create_async_engine(settings.database_url)
    app.state.db_engine = engine
    app.state.session_factory = async_sessionmaker(
        engine,
        class_=AsyncSession,
        expire_on_commit=False,
    )

    async with engine.begin() as conn:
        await conn.run_sync(SQLModel.metadata.create_all)
    logger.info("Database tables verified")

    await redis_manager.connect()

    geoip = GeoIPService(settings.geoip_db_path)

    redis_client = redis_manager.client
    assert redis_client is not None

    dispatcher = AlertDispatcher(
        redis_client=redis_client,
        session_factory=app.state.session_factory,
    )

    inference_engine = _load_inference_engine()
    app.state.models_loaded = (
        inference_engine is not None
        and inference_engine.is_loaded
    )
    app.state.detection_mode = (
        "hybrid"
        if app.state.models_loaded
        else "rules"
    )

    pipeline = Pipeline(
        redis_client=redis_client,  # type: ignore[arg-type]
        rule_engine=RuleEngine(),
        geoip=geoip,
        on_result=dispatcher.dispatch,
        inference_engine=inference_engine,
        ensemble_weights={
            "ae": settings.ensemble_weight_ae,
            "rf": settings.ensemble_weight_rf,
            "if": settings.ensemble_weight_if,
        },
        raw_queue_size=settings.raw_queue_size,
        parsed_queue_size=settings.parsed_queue_size,
        feature_queue_size=settings.feature_queue_size,
        alert_queue_size=settings.alert_queue_size,
    )
    await pipeline.start()

    tailer = None
    log_dir = Path(settings.nginx_log_path).resolve().parent
    if log_dir.is_dir():
        loop = asyncio.get_running_loop()
        tailer = LogTailer(settings.nginx_log_path, pipeline.raw_queue, loop)
        tailer.start()
    else:
        logger.warning("Log directory %s not found — tailer disabled", log_dir)

    app.state.pipeline = pipeline
    app.state.tailer = tailer
    app.state.geoip = geoip
    app.state.pipeline_running = True

    logger.info("AngelusVigil started — pipeline active")

    yield

    app.state.pipeline_running = False
    if tailer is not None:
        tailer.stop()
    await pipeline.stop()
    geoip.close()
    await redis_manager.disconnect()
    await engine.dispose()

    logger.info("AngelusVigil shut down cleanly")
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The function has a time complexity of \(O(1)\) for most operations, but the `create_async_engine`, `conn.run_sync(SQLModel.metadata.create_all)`, and `pipeline.start()` calls can introduce significant overhead due to database initialization and pipeline setup.

**Space Complexity:** The space complexity is also \(O(1)\) as the state variables are stored in the application's state. However, the `LogTailer` instance might consume additional memory if the log directory contains a large number of files.

**Bottlenecks or Inefficiencies:**
- **Blocking Calls:** The `await conn.run_sync(SQLModel.metadata.create_all)` and `pipeline.start()` calls are blocking and could be optimized by ensuring they do not block the event loop unnecessarily.
- **Redundant Operations:** The `logger.info` statements are frequent but non-blocking. However, consider batching logs if performance becomes an issue.

**Optimization Opportunities:**
- Use `asyncio.create_task` to run database initialization and pipeline setup concurrently where possible.
- Implement connection pooling for the database engine to reduce overhead from repeated connections.

**Resource Usage Concerns:**
- Ensure that all resources like the database engine, session factory, and log tailer are properly closed using context managers or explicit `await` calls. The current implementation uses `await engine.dispose()` which is good.
- Consider adding error handling for critical sections to ensure proper cleanup in case of exceptions.

By addressing these points, you can improve both the performance and robustness of your application startup process.

---

*Generated by CodeWorm on 2026-02-27 23:07*
