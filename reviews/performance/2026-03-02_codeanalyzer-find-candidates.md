# CodeAnalyzer.find_candidates

**Type:** Performance Analysis
**Repository:** CodeWorm
**File:** codeworm/analysis/analyzer.py
**Language:** python
**Lines:** 228-251
**Complexity:** 9.0

---

## Source Code

```python
def find_candidates(
        self,
        repo: RepoEntry | None = None,
        limit: int = 50,
    ) -> list[AnalysisCandidate]:
        """
        Find documentation candidates from repositories
        """
        candidates: list[AnalysisCandidate] = []

        repos_to_scan = [repo] if repo else [r for r in self.repos if r.enabled]

        for repo_config in repos_to_scan:
            for scanned_file in self.scanner.scan_repo(repo_config.path,
                                                       repo_config.name):
                for candidate in self.analyze_file(scanned_file):
                    if candidate.is_worth_documenting:
                        candidates.append(candidate)

                    if len(candidates) >= limit * 3:
                        break

        candidates.sort(key = lambda c: c.score, reverse = True)
        return candidates[: limit]
```

---

## Performance Analysis

### Performance Analysis

#### Time Complexity
The time complexity of `find_candidates` is \(O(n \cdot m)\), where \(n\) is the number of repositories to scan, and \(m\) is the average number of files per repository. The nested loops over files and candidates contribute significantly.

#### Space Complexity
Space complexity is \(O(k + l)\), where \(k\) is the total size of `repos_to_scan` and \(l\) is the length of `candidates`. The list comprehension to filter enabled repositories might be costly if `self.repos` is large.

#### Bottlenecks or Inefficiencies
1. **Nested Loops**: The nested loops over files and candidates can become a bottleneck, especially with many repositories and files.
2. **Unnecessary Iterations**: The innermost loop iterates over all candidates in each file, even if the limit of 3x is reached early.

#### Optimization Opportunities
1. **Early Exit**: Use `break` more effectively to exit nested loops once the candidate limit is met.
2. **Filter Early**: Apply filtering for `is_worth_documenting` earlier to reduce unnecessary operations.
3. **Limit Iteration**: Introduce a counter in the innermost loop to break early if the limit is reached.

#### Resource Usage Concerns
- Ensure that file handles are properly managed, especially if `self.scanner.scan_repo` opens files.
- Consider using context managers for file handling and closing database connections if any are used internally.

### Suggested Optimizations

```python
def find_candidates(
        self,
        repo: RepoEntry | None = None,
        limit: int = 50,
    ) -> list[AnalysisCandidate]:
    candidates: list[AnalysisCandidate] = []

    repos_to_scan = [repo] if repo else [r for r in self.repos if r.enabled]

    for repo_config in repos_to_scan:
        scanned_files = self.scanner.scan_repo(repo_config.path, repo_config.name)
        for candidate in (c for c in self.analyze_file(scanned_files) if c.is_worth_documenting):
            candidates.append(candidate)
            if len(candidates) >= limit * 3:
                break

    candidates.sort(key=lambda c: c.score, reverse=True)
    return candidates[:limit]
```

This refines the logic to exit early and reduces unnecessary iterations.

---

*Generated by CodeWorm on 2026-03-02 09:46*
