# print_batch_results

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/beginner/dns-lookup/dnslookup/output.py
**Language:** python
**Lines:** 269-328
**Complexity:** 13.0

---

## Source Code

```python
def print_batch_results(results: list[DNSResult]) -> None:
    """
    Display batch lookup results in a summary table
    """
    table = Table(
        title = "[bold]Batch Results[/bold]",
        box = box.ROUNDED,
        border_style = "blue",
        row_styles = ["",
                      "dim"],
    )

    table.add_column("Domain", style = "cyan", min_width = 25)
    table.add_column("A", justify = "center", width = 15)
    table.add_column("MX", justify = "center", width = 5)
    table.add_column("NS", justify = "center", width = 5)
    table.add_column(
        "Time",
        justify = "right",
        style = "dim",
        width = 8
    )

    for result in results:
        a_records = [
            r for r in result.records if r.record_type == RecordType.A
        ]
        mx_count = len(
            [
                r for r in result.records
                if r.record_type == RecordType.MX
            ]
        )
        ns_count = len(
            [
                r for r in result.records
                if r.record_type == RecordType.NS
            ]
        )

        a_value = a_records[0].value if a_records else "[dim]-[/dim]"
        mx_value = str(mx_count) if mx_count else "[dim]-[/dim]"
        ns_value = str(ns_count) if ns_count else "[dim]-[/dim]"

        table.add_row(
            result.domain,
            a_value,
            mx_value,
            ns_value,
            f"{result.query_time_ms:.0f}ms",
        )

    console.print(table)

    total_records = sum(len(r.records) for r in results)
    total_time = sum(r.query_time_ms for r in results)
    console.print(
        f"\n[green]:heavy_check_mark:[/green] {len(results)} domains, {total_records} total records in {total_time:.0f}ms"
    )
    console.print()
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The function has a time complexity of \(O(n \cdot m)\), where \(n\) is the number of `DNSResult` objects, and \(m\) is the average number of records per result. This is due to the nested list comprehensions used for filtering records.

**Space Complexity:** The space complexity is \(O(n + k)\), where \(k\) is the total number of records across all results. Each `DNSResult` object's records are processed, but no additional data structures with a size dependent on input are used.

**Bottlenecks or Inefficiencies:**
- **Nested List Comprehensions:** The nested list comprehensions for filtering records (`a_records`, `mx_count`, `ns_count`) can be costly if the number of records is large.
- **Redundant Operations:** Calculating `a_value`, `mx_value`, and `ns_value` multiple times for each result.

**Optimization Opportunities:**
1. **Use Generators:** Replace list comprehensions with generators to avoid unnecessary memory allocation:
   ```python
   a_records = (r for r in result.records if r.record_type == RecordType.A)
   mx_count = sum(1 for r in result.records if r.record_type == RecordType.MX)
   ns_count = sum(1 for r in result.records if r.record_type == RecordType.NS)
   ```

2. **Memoization:** Cache the results of `len(result.records)` to avoid redundant calculations.

**Resource Usage Concerns:**
- Ensure that `console.print` and other I/O operations are efficient, especially when dealing with large datasets.
- Consider using a more efficient table library if the current one is not optimized for performance.

---

*Generated by CodeWorm on 2026-02-19 16:08*
