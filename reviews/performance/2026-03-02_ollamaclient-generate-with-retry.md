# OllamaClient.generate_with_retry

**Type:** Performance Analysis
**Repository:** CodeWorm
**File:** codeworm/llm/client.py
**Language:** python
**Lines:** 214-245
**Complexity:** 8.0

---

## Source Code

```python
async def generate_with_retry(
        self,
        prompt: str,
        system: str | None = None,
        max_retries: int = 3,
        retry_delay: float = 2.0,
    ) -> GenerationResult:
        """
        Generate with automatic retry on transient failures
        """
        last_error: Exception | None = None

        for attempt in range(max_retries):
            try:
                return await self.generate(prompt, system)

            except OllamaModelError:
                logger.warning("model_oom_detected", attempt = attempt + 1)
                await self._recover_from_oom()
                last_error = OllamaModelError("Model OOM after recovery attempt")

            except OllamaTimeoutError as e:
                last_error = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (attempt + 1))

            except OllamaConnectionError as e:
                last_error = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (attempt + 1))

        raise last_error or OllamaError("Generation failed after retries")
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity**: The time complexity is \(O(n \times m)\), where \(n\) is the number of retries (up to `max_retries`), and \(m\) is the time taken for each retry attempt, including any delays (`retry_delay * (attempt + 1)`). This can lead to exponential growth in execution time if retries are frequent.

**Space Complexity**: The space complexity is \(O(1)\) as there are no significant data structures that grow with input size. However, the function uses a local variable `last_error` which does not consume additional memory proportional to input size.

**Bottlenecks and Inefficiencies**:
- **Redundant Logging**: The `logger.warning` call is repeated in each retry attempt, leading to unnecessary logging.
- **Delay Calculation**: The delay calculation (`retry_delay * (attempt + 1)`) can be optimized by using a precomputed list of delays to avoid multiplication.

**Optimization Opportunities**:
- **Reduce Redundant Logging**: Log the error only once after all retries are exhausted.
- **Precompute Delays**: Store the delay values in a list and use them directly, reducing the computational overhead.

```python
async def generate_with_retry(
        self,
        prompt: str,
        system: str | None = None,
        max_retries: int = 3,
        retry_delay: float = 2.0,
    ) -> GenerationResult:
    delays = [retry_delay * (i + 1) for i in range(max_retries)]
    
    last_error: Exception | None = None
    for attempt, delay in zip(range(max_retries), delays):
        try:
            return await self.generate(prompt, system)
        
        except OllamaModelError:
            logger.warning("model_oom_detected", attempt=attempt + 1)
            await self._recover_from_oom()
            last_error = OllamaModelError("Model OOM after recovery attempt")

        except (OllamaTimeoutError, OllamaConnectionError) as e:
            last_error = e
            if attempt < max_retries - 1:
                await asyncio.sleep(delay)
    
    raise last_error or OllamaError("Generation failed after retries")
```

**Resource Usage Concerns**: Ensure that `self._recover_from_oom()` does not hold any locks or resources that could cause blocking. Use context managers if necessary to ensure proper resource cleanup.

By optimizing the logging and delay calculation, you can improve both performance and readability of the code.

---

*Generated by CodeWorm on 2026-03-02 09:10*
