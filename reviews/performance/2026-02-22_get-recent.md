# get_recent

**Type:** Performance Analysis
**Repository:** CodeWorm
**File:** dashboard/backend/api.py
**Language:** python
**Lines:** 149-197
**Complexity:** 8.0

---

## Source Code

```python
async def get_recent(
    limit: int = Query(default=50, ge=1, le=200),
    offset: int = Query(default=0, ge=0),
    repo: str | None = Query(default=None),
    doc_type: str | None = Query(default=None),
) -> list[RecentDoc]:
    db = _get_db_path()
    if not db.exists():
        return []

    query = "SELECT * FROM documented_snippets"
    params: list = []
    conditions: list[str] = []
    has_doc_type = False

    with _get_conn() as check_conn:
        has_doc_type = _has_column(check_conn, "documented_snippets", "doc_type")

    if repo:
        conditions.append("source_repo = ?")
        params.append(repo)
    if doc_type and has_doc_type:
        conditions.append("doc_type = ?")
        params.append(doc_type)

    if conditions:
        query += " WHERE " + " AND ".join(conditions)

    query += " ORDER BY documented_at DESC LIMIT ? OFFSET ?"
    params.extend([limit, offset])

    with _get_conn() as conn:
        rows = conn.execute(query, params).fetchall()

    results = []
    for row in rows:
        results.append(RecentDoc(
            id=row["id"],
            source_repo=row["source_repo"],
            source_file=row["source_file"],
            function_name=row["function_name"],
            class_name=row["class_name"],
            doc_type=row["doc_type"] if "doc_type" in row.keys() else "function_doc",
            documented_at=row["documented_at"],
            snippet_path=row["snippet_path"],
            git_commit=row["git_commit"],
        ))

    return results
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The time complexity is O(n + m), where `n` is the number of rows returned by the database query, and `m` is the number of operations to create `RecentDoc` instances.

**Space Complexity:** The space complexity is O(m) due to storing the results in memory. The use of context managers for database connections ensures proper resource management but could be optimized further.

**Bottlenecks or Inefficiencies:**
1. **Redundant Database Connection:** Opening a new connection inside `_get_conn()` for checking column existence is unnecessary and can lead to performance degradation.
2. **N+1 Query Pattern:** The code fetches all rows in one query but then processes each row individually, which could be optimized by fetching the required fields only.

**Optimization Opportunities:**
1. **Pre-fetch Column Existence:** Check if `doc_type` exists before executing the main query to avoid redundant database calls.
2. **Selective Fetching:** Modify the SQL query to fetch only necessary columns to reduce memory usage and improve performance.

**Resource Usage Concerns:**
- Ensure `_get_db_path()` and `_has_column()` are efficient and do not introduce blocking operations in async contexts.
- Consider using a connection pool for database connections to avoid repeated connection overhead.

By addressing these issues, the code can be made more efficient and performant.

---

*Generated by CodeWorm on 2026-02-22 08:51*
