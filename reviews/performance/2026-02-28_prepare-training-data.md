# prepare_training_data

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/advanced/ai-threat-detection/backend/ml/splitting.py
**Language:** python
**Lines:** 28-84
**Complexity:** 4.0

---

## Source Code

```python
def prepare_training_data(
    X: np.ndarray,
    y: np.ndarray,
    train_ratio: float = 0.70,
    val_ratio: float = 0.15,
    smote_strategy: float = 0.3,
    smote_k: int = 5,
    random_state: int = 42,
) -> TrainingSplit:
    """
    Split data into train/val/test with SMOTE on training set only
    """
    n_classes = len(np.unique(y))
    if n_classes < 2:
        raise ValueError("y must contain at least 2 classes")

    test_size = 1.0 - train_ratio
    X_train, X_rem, y_train, y_rem = train_test_split(
        X,
        y,
        test_size=test_size,
        stratify=y,
        random_state=random_state,
    )

    X_val, X_test, y_val, y_test = train_test_split(
        X_rem,
        y_rem,
        test_size=0.5,
        stratify=y_rem,
        random_state=random_state,
    )

    X_normal_train = X_train[y_train == 0]

    class_counts = np.bincount(y_train)
    minority_count = class_counts.min()
    majority_count = class_counts.max()
    current_ratio = minority_count / majority_count

    if (minority_count >= smote_k + 1 and current_ratio < smote_strategy):
        sampler = SMOTE(
            sampling_strategy=smote_strategy,
            k_neighbors=smote_k,
            random_state=random_state,
        )
        X_train, y_train = sampler.fit_resample(X_train, y_train)

    return TrainingSplit(
        X_train=X_train,
        y_train=y_train,
        X_val=X_val,
        y_val=y_val,
        X_test=X_test,
        y_test=y_test,
        X_normal_train=X_normal_train,
    )
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The primary bottleneck is the `train_test_split` function calls, which have a time complexity of \(O(n)\) for each split operation. The SMOTE resampling step has a time complexity of \(O(m \cdot k^2)\), where \(m\) is the number of minority class samples and \(k\) is the number of neighbors considered.

**Space Complexity:** The function creates multiple copies of data arrays, leading to high memory usage, especially for large datasets. The `X_normal_train` array can consume significant space if the majority class dominates.

**Bottlenecks or Inefficiencies:**
- **Redundant Operations:** The `np.unique(y)` call is repeated unnecessarily.
- **Multiple `train_test_split` Calls:** Splitting data multiple times increases both time and space complexity without clear benefits.
- **SMOTE Resampling:** This step can be costly, especially for large datasets.

**Optimization Opportunities:**
- Use a single `train_test_split` call to get train/val/test splits directly.
- Cache the result of `np.unique(y)` if it is used multiple times.
- Implement SMOTE only once and use incremental resampling techniques if applicable.

**Resource Usage Concerns:**
- Ensure that large arrays are managed efficiently, possibly using generators or chunking data for very large datasets.
- Consider using more memory-efficient data structures like sparse matrices if the dataset has many zero values.

---

*Generated by CodeWorm on 2026-02-28 08:52*
