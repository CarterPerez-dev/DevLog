# peel

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/beginner/base64-tool/src/base64_tool/peeler.py
**Language:** python
**Lines:** 55-99
**Complexity:** 7.0

---

## Source Code

```python
def peel(
    data: str,
    *,
    max_depth: int = PEEL_MAX_DEPTH,
    threshold: float = CONFIDENCE_THRESHOLD,
    verbose: bool = False,
) -> PeelResult:
    layers: list[PeelLayer] = []
    current_text = data
    current_bytes = data.encode("utf-8")

    for depth in range(max_depth):
        detection = detect_best(current_text)

        if detection is None:
            break
        if detection.confidence < threshold:
            break
        if detection.decoded is None:
            break

        scores = (tuple(score_all_formats(current_text).items()) if verbose else ())

        decoded_bytes = detection.decoded
        layer = PeelLayer(
            depth = depth + 1,
            format = detection.format,
            confidence = detection.confidence,
            encoded_preview = truncate(current_text),
            decoded_preview = safe_bytes_preview(decoded_bytes),
            all_scores = scores,
        )
        layers.append(layer)
        current_bytes = decoded_bytes

        try:
            current_text = decoded_bytes.decode("utf-8")
        except (UnicodeDecodeError, ValueError):
            break

    return PeelResult(
        layers = tuple(layers),
        final_output = current_bytes,
        success = len(layers) > 0,
    )
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The time complexity is primarily driven by the `detect_best`, `score_all_formats`, and `decode` operations, each of which can be costly depending on their implementation. The loop runs up to `max_depth` times, making it O(max_depth * n), where n is the cost of internal operations.

**Space Complexity:** The space complexity is O(n) due to the storage of `layers` list and `current_bytes`. Memory usage could increase significantly if `data` is large or `max_depth` is high.

**Bottlenecks:**
1. **Redundant Operations:** The loop checks conditions multiple times, which can be optimized.
2. **Blocking Decoding:** The `decode` operation inside the loop can block and retry on failure, impacting performance.

**Optimization Opportunities:**
1. **Early Breaks:** Combine redundant break conditions into one check to reduce branching.
2. **Async Decoding:** Use asynchronous decoding methods if available to avoid blocking.
3. **Memoization:** Cache results of `detect_best` and `score_all_formats` to avoid repeated computations.

**Resource Usage Concerns:**
- Ensure proper handling of exceptions in the `decode` operation to prevent resource leaks.
- Consider using context managers for any file or network operations, even though none are present here.

---

*Generated by CodeWorm on 2026-02-28 16:53*
