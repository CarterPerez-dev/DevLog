# RuleEngine.score_request

**Type:** Performance Analysis
**Repository:** Cybersecurity-Projects
**File:** PROJECTS/advanced/ai-threat-detection/backend/app/core/detection/rules.py
**Language:** python
**Lines:** 91-135
**Complexity:** 13.0

---

## Source Code

```python
def score_request(
        self,
        features: dict[str, int | float | bool | str],
        entry: ParsedLogEntry,
    ) -> RuleResult:
        """
        Evaluate all rules against a request and return a composite score.
        """
        matched: list[tuple[str, float]] = []

        uri = entry.path
        if entry.query_string:
            uri = f"{entry.path}?{entry.query_string}"

        for rule in _PATTERN_RULES:
            if rule.pattern.search(uri):
                matched.append((rule.name, rule.score))

        if DOUBLE_ENCODED.search(uri):
            matched.append(("DOUBLE_ENCODING", _DOUBLE_ENCODING_SCORE))

        ua_lower = entry.user_agent.lower()
        if any(sig in ua_lower for sig in SCANNER_USER_AGENTS):
            matched.append(("SCANNER_UA", _SCANNER_UA_SCORE))

        for trule in _THRESHOLD_RULES:
            value = features.get(trule.feature_key, 0)
            if isinstance(value, int | float) and value > trule.threshold:
                matched.append((trule.name, trule.score))

        if not matched:
            return RuleResult(threat_score=0.0, severity="LOW")

        scores = sorted([s for _, s in matched], reverse=True)
        threat_score = min(
            scores[0] + _BOOST_PER_ADDITIONAL_RULE * (len(scores) - 1),
            1.0,
        )

        return RuleResult(
            threat_score=threat_score,
            severity=_classify_severity(threat_score),
            matched_rules=[name for name, _ in matched],
            component_scores=dict(matched),
        )
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** O(n + m), where `n` is the number of rules in `_PATTERN_RULES`, and `m` is the number of threshold rules in `_THRESHOLD_RULES`. The time complexity is linear due to the iterations over these lists.

**Space Complexity:** O(k), where `k` is the number of matched rules. The space used for storing `matched` grows with the number of matching rules.

**Bottlenecks and Inefficiencies:**
- **Redundant Iterations:** The function iterates over `_PATTERN_RULES` and `_THRESHOLD_RULES`, which can be costly if these lists are large.
- **String Concatenation:** `uri = f"{entry.path}?{entry.query_string}"` is inefficient as it creates a new string each time. Use `uri += entry.query_string` instead.

**Optimization Opportunities:**
- **Memoization:** Cache the results of `DOUBLE_ENCODED.search(uri)` and `any(sig in ua_lower for sig in SCANNER_USER_AGENTS)` to avoid redundant checks.
- **Early Exit:** If a high-severity rule matches, consider returning early to reduce unnecessary processing.

**Resource Usage Concerns:**
- Ensure `_PATTERN_RULES` and `_THRESHOLD_RULES` are properly managed. Consider using generators or lazy loading if these lists are very large.
- Use context managers for any file or database operations that might be present in the `RuleResult` class to prevent resource leaks.

By addressing these points, you can improve both the performance and maintainability of your code.

---

*Generated by CodeWorm on 2026-02-19 13:49*
