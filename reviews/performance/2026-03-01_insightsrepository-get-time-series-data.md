# InsightsRepository.get_time_series_data

**Type:** Performance Analysis
**Repository:** angelamos-operations
**File:** CarterOS-Server/src/aspects/analytics/facets/insights/repository.py
**Language:** python
**Lines:** 432-469
**Complexity:** 3.0

---

## Source Code

```python
async def get_time_series_data(cls,
                                   session: AsyncSession) -> list[dict]:
        """Get performance metrics over time"""
        videos = await cls.get_all_videos(session)

        # Group by date
        date_stats = defaultdict(
            lambda: {
                "views": 0,
                "engagement": 0,
                "new_followers": 0,
                "count": 0,}
        )

        for video in videos:
            date_str = video.date_posted.isoformat()
            engagement_rate = cls.calculate_engagement_rate(video)

            date_stats[date_str]["views"] += video.views
            date_stats[date_str]["engagement"] += engagement_rate
            date_stats[date_str]["new_followers"] += video.new_followers
            date_stats[date_str]["count"] += 1

        # Convert to list and calculate averages
        result = []
        for date_str, stats in sorted(date_stats.items()):
            count = stats["count"]
            result.append(
                {
                    "date": date_str,
                    "views": stats["views"],
                    "engagement_rate": stats["engagement"] / count,
                    "new_followers": stats["new_followers"],
                    "video_count": count,
                }
            )

        return result
```

---

## Performance Analysis

### Performance Analysis

**Time Complexity:** The time complexity is \(O(n \cdot m)\), where \(n\) is the number of videos, and \(m\) is the average number of stats calculated per video (in this case, 1). The bottleneck is in the nested loop that aggregates statistics by date.

**Space Complexity:** The space complexity is also \(O(n \cdot m)\) due to storing intermediate results in `date_stats`. This can be memory-intensive for large datasets.

**Bottlenecks or Inefficiencies:**
- **Redundant Operations:** Calculating the engagement rate and other stats repeatedly within the loop.
- **Unnecessary Iterations:** The nested loop iterates over each video multiple times, which is inefficient.

**Optimization Opportunities:**
- **Calculate Engagement Rate Once:** Store calculated values to avoid redundant computations.
- **Use Generators:** Use generators to process data in chunks rather than loading everything into memory at once.

**Resource Usage Concerns:**
- Ensure `AsyncSession` and other resources are properly managed using context managers or async context decorators to prevent leaks.

### Suggested Optimizations

1. **Memoize Engagement Rate Calculation:**
   ```python
   @functools.lru_cache(maxsize=None)
   def calculate_engagement_rate(video):
       return cls.calculate_engagement_rate(video)
   ```

2. **Use Generators for Large Datasets:**
   ```python
   async def get_time_series_data(cls, session: AsyncSession) -> list[dict]:
       videos = await cls.get_all_videos(session)

       date_stats = defaultdict(
           lambda: {
               "views": 0,
               "engagement": 0,
               "new_followers": 0,
               "count": 0,
           }
       )

       for video in videos:
           date_str = video.date_posted.isoformat()
           engagement_rate = calculate_engagement_rate(video)

           date_stats[date_str]["views"] += video.views
           date_stats[date_str]["engagement"] += engagement_rate
           date_stats[date_str]["new_followers"] += video.new_followers
           date_stats[date_str]["count"] += 1

       result = []
       for date_str, stats in sorted(date_stats.items()):
           count = stats["count"]
           result.append(
               {
                   "date": date_str,
                   "views": stats["views"],
                   "engagement_rate": stats["engagement"] / count,
                   "new_followers": stats["new_followers"],
                   "video_count": count,
               }
           )

       return result
   ```

3. **Ensure Proper Resource Management:**
   ```python
   async with session:
       # Use the session within this context
   ```

By implementing these changes, you can significantly improve the efficiency and resource management of your code.

---

*Generated by CodeWorm on 2026-03-01 14:01*
