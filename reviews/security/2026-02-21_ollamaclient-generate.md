# OllamaClient.generate

**Type:** Security Review
**Repository:** CodeWorm
**File:** codeworm/llm/client.py
**Language:** python
**Lines:** 147-212
**Complexity:** 11.0

---

## Source Code

```python
async def generate(
        self,
        prompt: str,
        system: str | None = None,
        temperature: float | None = None,
        max_tokens: int | None = None,
    ) -> GenerationResult:
        """
        Generate text from a prompt
        """
        client = await self._get_client()

        options = {
            "temperature": temperature or self.settings.temperature,
            "num_predict": max_tokens or self.settings.num_predict,
            "num_ctx": self.settings.num_ctx,
        }

        payload = {
            "model": self.settings.model,
            "prompt": prompt,
            "stream": False,
            "keep_alive": self.settings.keep_alive,
            "options": options,
        }

        if system:
            payload["system"] = system

        try:
            response = await client.post("/api/generate", json = payload)

            if response.status_code != 200:
                error_text = response.text
                if "out of memory" in error_text.lower(
                ) or "cuda" in error_text.lower():
                    raise OllamaModelError(f"Model OOM: {error_text}")
                raise OllamaError(f"Generation failed: {error_text}")

            data = response.json()

            prompt_tokens = data.get("prompt_eval_count", 0)
            completion_tokens = data.get("eval_count", 0)
            total_duration = data.get("total_duration", 0) / 1_000_000

            tokens_per_sec = 0.0
            if total_duration > 0 and completion_tokens > 0:
                tokens_per_sec = completion_tokens / (total_duration / 1000)

            return GenerationResult(
                text = data.get("response",
                                ""),
                model = data.get("model",
                                 self.settings.model),
                prompt_tokens = prompt_tokens,
                completion_tokens = completion_tokens,
                total_duration_ms = int(total_duration),
                tokens_per_second = tokens_per_sec,
            )

        except httpx.ConnectError as e:
            raise OllamaConnectionError(
                f"Cannot connect to Ollama at {self.base_url}: {e}"
            ) from e
        except httpx.TimeoutException as e:
            raise OllamaTimeoutError(f"Request timed out: {e}") from e
```

---

## Security Review

### Security Review for `OllamaClient.generate`

**Vulnerabilities:**

1. **HTTP Response Handling (Info):**
   - The error handling could be improved to avoid exposing sensitive information.
   - **Severity:** Info

2. **Error Messages (Info):**
   - Error messages might leak details about the system, such as model OOM issues.

3. **Hardcoded Secrets (Low):**
   - Ensure no hardcoded secrets or credentials are present in the settings.

4. **Input Validation (Medium):**
   - Validate `prompt`, `system`, and other inputs to prevent injection attacks.
   - **Severity:** Medium

5. **Error Handling (Info):**
   - The current error handling is basic and could be more robust.

**Attack Vectors:**

- An attacker could exploit input validation gaps to inject malicious data, leading to unexpected behavior or security issues.
- Error messages might reveal sensitive information about the system.

**Recommended Fixes:**

1. **Input Validation:**
   ```python
   def validate_input(input_str: str) -> bool:
       # Implement validation logic here
       return True

   if not validate_input(prompt):
       raise ValueError("Invalid input")
   ```

2. **Enhanced Error Handling:**
   - Use structured error handling to avoid exposing sensitive information.
   ```python
   try:
       response = await client.post("/api/generate", json=payload)
       # ... existing code ...
   except httpx.HTTPStatusError as e:
       raise OllamaError(f"HTTP Status Error: {e.response.status_code}") from e
   ```

3. **Review Settings for Hardcoded Secrets:**
   - Ensure no hardcoded secrets are present in the settings.

**Overall Security Posture:**

The code has some basic security issues, particularly around input validation and error handling. Addressing these will improve the overall security posture of the application.

---

*Generated by CodeWorm on 2026-02-21 15:56*
