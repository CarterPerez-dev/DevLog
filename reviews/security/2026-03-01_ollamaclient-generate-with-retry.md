# OllamaClient.generate_with_retry

**Type:** Security Review
**Repository:** CodeWorm
**File:** codeworm/llm/client.py
**Language:** python
**Lines:** 214-245
**Complexity:** 8.0

---

## Source Code

```python
async def generate_with_retry(
        self,
        prompt: str,
        system: str | None = None,
        max_retries: int = 3,
        retry_delay: float = 2.0,
    ) -> GenerationResult:
        """
        Generate with automatic retry on transient failures
        """
        last_error: Exception | None = None

        for attempt in range(max_retries):
            try:
                return await self.generate(prompt, system)

            except OllamaModelError:
                logger.warning("model_oom_detected", attempt = attempt + 1)
                await self._recover_from_oom()
                last_error = OllamaModelError("Model OOM after recovery attempt")

            except OllamaTimeoutError as e:
                last_error = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (attempt + 1))

            except OllamaConnectionError as e:
                last_error = e
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay * (attempt + 1))

        raise last_error or OllamaError("Generation failed after retries")
```

---

## Security Review

### Security Review for `generate_with_retry`

#### Vulnerabilities and Severity:

1. **Info - No Injection**: The function does not appear to handle user input in a way that could lead to injection vulnerabilities.
   
2. **Info - Error Handling**: The error handling is robust but could potentially leak information about transient failures, which might be useful for an attacker.

3. **Info - Retry Logic**: The retry logic with exponential backoff can help prevent abuse by rate-limiting repeated requests from a single source.

#### Attack Vectors:

- An attacker could exploit the error messages to understand the system's behavior and potentially identify specific failure points.
- If `OllamaModelError`, `OllamaTimeoutError`, or `OllamaConnectionError` are not properly sanitized, they might contain sensitive information.

#### Recommended Fixes:

1. **Sanitize Error Messages**: Ensure that any error messages returned to the client do not include detailed stack traces or other potentially sensitive information.
   ```python
   except OllamaModelError as e:
       last_error = "Model encountered an issue during processing."
   ```

2. **Logging Improvements**: Use structured logging for errors, which can be configured to omit sensitive details in production environments.
   ```python
   import structlog

   logger = structlog.get_logger()

   async def generate_with_retry(...):
       ...
       except OllamaModelError:
           logger.warning("model_error", attempt=attempt + 1)
           await self._recover_from_oom()
   ```

3. **Review and Secure Dependencies**: Ensure that all dependencies like `OllamaModelError`, `OllamaTimeoutError`, and `OllamaConnectionError` are secure and do not expose sensitive information.

#### Overall Security Posture:

The current implementation is relatively secure but can be improved by reducing the potential for information leakage. Proper error handling and structured logging will enhance the security posture of this function.

---

*Generated by CodeWorm on 2026-03-01 16:22*
